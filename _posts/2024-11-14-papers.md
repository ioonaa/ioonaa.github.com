---
layout: post

title: Two articles hot off the press! &#128680; 
---

If you wonder how users of ChatGPT perceive the system's communicative abilities and how this perception is shaped by first-hand
experience with the system, have a look at our article <a href="https://doi.org/10.1016/j.ijhcs.2024.103400" target="_blank" rel="noopener"><strong>
ChatGPT and me: First-time and experienced users’ perceptions of ChatGPT’s communicative ability as a dialogue partner</strong></a> with
<strong>Katie Seaborn</strong> (Tokyo Institute of Technology, Japan), <strong>Maddy Steeds</strong>, and 
<strong>Ben Cowan</strong> (University College Dublin, Ireland). This article is &#128214; <em>#openaccess</em> &#128275; <strong>until January 03, 2025</strong> via <a href="https://authors.elsevier.com/a/1k5yZ3pfaRxOWi" target="_blank" rel="noopener"><strong>this link</strong></a>.

Would you consider using automatic speech recognition (ASR) for the transcription of conversational speech data? 
You may be interested to read about <a href="https://doi.org/10.1016/j.rmal.2024.100163" target="_blank" rel="noopener"><strong>
What ASR can and cannot do for conversational speech transcription</strong></a> in our article with
<strong>Sam O'Connor Russell</strong> and <strong>Naomi Harte</strong> (Trinty College Dublin, Ireland), <strong>Anna Krason</strong> 
(Moss Rehabilitation Research Institute, USA), and <strong>Gabriella Vigliocco</strong> (University College London, UK). This article is &#128214; <em>#openaccess</em> &#128275;



